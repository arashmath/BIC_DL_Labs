{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2tvbt-GCAIB"
      },
      "source": [
        "# F29BC: Bio-Inspired Computation\n",
        "\n",
        "- FFNN\n",
        "- CNN\n",
        "- RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWiskADtBF4u"
      },
      "source": [
        "## Feed-Forward Neural Network\n",
        "\n",
        "Trains a simple deep NN on the MNIST dataset.\n",
        "\n",
        "Gets to 98.40% test accuracy after 20 epochs\n",
        "(there is **a lot** of margin for parameter tuning).\n",
        "\n",
        "2 seconds per epoch on a K520 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxvlsTj2B73H"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import RMSprop\n",
        "from keras.metrics import Precision, Recall"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2UcvIjAJC-U2"
      },
      "outputs": [],
      "source": [
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 20\n",
        "\n",
        "keras.utils.set_random_seed(7) # set `seed` for regeneration purposes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfmdREw0CN_Z",
        "outputId": "944ea10f-31a7-4937-b65a-398de35e9b51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 2s 0us/step\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ]
        }
      ],
      "source": [
        "# loading data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000, 784)\n",
        "x_test = x_test.reshape(10000, 784)\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm-acwTYD-91",
        "outputId": "198f2b43-658a-4ea5-b599-49e57ff0421e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 512)               401920    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 669706 (2.55 MB)\n",
            "Trainable params: 669706 (2.55 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(512, activation='relu', input_shape=(784,)))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(512, activation='relu'))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EI01dfAwJh34"
      },
      "outputs": [],
      "source": [
        "precision = Precision()\n",
        "recall = Recall()\n",
        "# f_one_score = (2*precision*recall) / (precision+recall)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d9TlLM3VEOZe"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMSprop(),\n",
        "              metrics=['accuracy', precision, recall])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NMcS1aB5BAbz",
        "outputId": "514de0d2-0c38-413c-e316-242051995599"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "469/469 [==============================] - 14s 12ms/step - loss: 0.2534 - accuracy: 0.9224 - precision: 0.9485 - recall: 0.9009 - val_loss: 0.0966 - val_accuracy: 0.9687 - val_precision: 0.9734 - val_recall: 0.9649\n",
            "Epoch 2/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.1026 - accuracy: 0.9692 - precision: 0.9737 - recall: 0.9651 - val_loss: 0.0726 - val_accuracy: 0.9762 - val_precision: 0.9792 - val_recall: 0.9741\n",
            "Epoch 3/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0733 - accuracy: 0.9767 - precision: 0.9799 - recall: 0.9747 - val_loss: 0.0685 - val_accuracy: 0.9797 - val_precision: 0.9818 - val_recall: 0.9777\n",
            "Epoch 4/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0565 - accuracy: 0.9824 - precision: 0.9840 - recall: 0.9806 - val_loss: 0.0741 - val_accuracy: 0.9782 - val_precision: 0.9796 - val_recall: 0.9772\n",
            "Epoch 5/20\n",
            "469/469 [==============================] - 2s 5ms/step - loss: 0.0460 - accuracy: 0.9855 - precision: 0.9869 - recall: 0.9844 - val_loss: 0.0631 - val_accuracy: 0.9823 - val_precision: 0.9837 - val_recall: 0.9817\n",
            "Epoch 6/20\n",
            "469/469 [==============================] - 3s 7ms/step - loss: 0.0412 - accuracy: 0.9870 - precision: 0.9882 - recall: 0.9860 - val_loss: 0.0618 - val_accuracy: 0.9830 - val_precision: 0.9849 - val_recall: 0.9823\n",
            "Epoch 7/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0334 - accuracy: 0.9896 - precision: 0.9904 - recall: 0.9889 - val_loss: 0.0684 - val_accuracy: 0.9819 - val_precision: 0.9825 - val_recall: 0.9814\n",
            "Epoch 8/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0282 - accuracy: 0.9913 - precision: 0.9918 - recall: 0.9910 - val_loss: 0.0643 - val_accuracy: 0.9845 - val_precision: 0.9850 - val_recall: 0.9836\n",
            "Epoch 9/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0246 - accuracy: 0.9922 - precision: 0.9927 - recall: 0.9919 - val_loss: 0.0776 - val_accuracy: 0.9827 - val_precision: 0.9832 - val_recall: 0.9822\n",
            "Epoch 10/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0228 - accuracy: 0.9923 - precision: 0.9927 - recall: 0.9920 - val_loss: 0.0670 - val_accuracy: 0.9841 - val_precision: 0.9848 - val_recall: 0.9838\n",
            "Epoch 11/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0200 - accuracy: 0.9938 - precision: 0.9941 - recall: 0.9936 - val_loss: 0.0768 - val_accuracy: 0.9836 - val_precision: 0.9842 - val_recall: 0.9831\n",
            "Epoch 12/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0198 - accuracy: 0.9939 - precision: 0.9941 - recall: 0.9937 - val_loss: 0.0805 - val_accuracy: 0.9819 - val_precision: 0.9826 - val_recall: 0.9816\n",
            "Epoch 13/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0180 - accuracy: 0.9944 - precision: 0.9945 - recall: 0.9941 - val_loss: 0.0793 - val_accuracy: 0.9813 - val_precision: 0.9817 - val_recall: 0.9811\n",
            "Epoch 14/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0160 - accuracy: 0.9948 - precision: 0.9950 - recall: 0.9947 - val_loss: 0.0771 - val_accuracy: 0.9839 - val_precision: 0.9845 - val_recall: 0.9834\n",
            "Epoch 15/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0162 - accuracy: 0.9946 - precision: 0.9948 - recall: 0.9944 - val_loss: 0.0789 - val_accuracy: 0.9843 - val_precision: 0.9849 - val_recall: 0.9841\n",
            "Epoch 16/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0131 - accuracy: 0.9955 - precision: 0.9956 - recall: 0.9954 - val_loss: 0.0765 - val_accuracy: 0.9854 - val_precision: 0.9862 - val_recall: 0.9853\n",
            "Epoch 17/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0126 - accuracy: 0.9959 - precision: 0.9960 - recall: 0.9958 - val_loss: 0.0716 - val_accuracy: 0.9853 - val_precision: 0.9858 - val_recall: 0.9851\n",
            "Epoch 18/20\n",
            "469/469 [==============================] - 3s 5ms/step - loss: 0.0116 - accuracy: 0.9963 - precision: 0.9964 - recall: 0.9962 - val_loss: 0.0810 - val_accuracy: 0.9844 - val_precision: 0.9848 - val_recall: 0.9840\n",
            "Epoch 19/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0123 - accuracy: 0.9959 - precision: 0.9961 - recall: 0.9958 - val_loss: 0.0780 - val_accuracy: 0.9856 - val_precision: 0.9859 - val_recall: 0.9856\n",
            "Epoch 20/20\n",
            "469/469 [==============================] - 2s 4ms/step - loss: 0.0108 - accuracy: 0.9962 - precision: 0.9963 - recall: 0.9962 - val_loss: 0.0886 - val_accuracy: 0.9836 - val_precision: 0.9844 - val_recall: 0.9835\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(x_train, y_train,\n",
        "                    batch_size=batch_size,\n",
        "                    epochs=epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46wpFjTIFXKq"
      },
      "source": [
        "- Difference between `model.evaluate()` and `model.predict()`: [here](https://stackoverflow.com/a/55049982/6306387)\n",
        "- **`verbose`**: ? type of animation for showing training progress?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TWMWSTYYFJh8",
        "outputId": "d565ef0e-29e7-4c1d-b07a-159a1bace1fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 3ms/step - loss: 0.0886 - accuracy: 0.9836 - precision: 0.9844 - recall: 0.9835\n",
            "Test loss: 0.08860217034816742\n",
            "Test accuracy: 0.9836000204086304\n",
            "Precision: 0.9843859672546387, Recall: 0.9835000038146973, F1-Score: 0.9839427860995309\n"
          ]
        }
      ],
      "source": [
        "score = model.evaluate(x_test, y_test, verbose='auto')\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "pres = score[2]\n",
        "recl = score[3]\n",
        "f_one = (2*pres*recl) / (pres+recl)\n",
        "print(f\"Precision: {pres}, Recall: {recl}, F1-Score: {f_one}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV48mO6eK2sv"
      },
      "source": [
        "- Another way to evaluate: getting model predictions and using sci-kit learn's `classification report`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "wVhldNDKLHsv",
        "outputId": "8f178fb2-b61f-41b3-eb8e-77c4e5ef2abd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a686cd8f99a6>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2308\u001b[0m     \"\"\"\n\u001b[1;32m   2309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2310\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2311\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m     96\u001b[0m             \"Classification metrics can't handle a mix of {0} and {1} targets\".format(\n\u001b[1;32m     97\u001b[0m                 \u001b[0mtype_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Classification metrics can't handle a mix of multilabel-indicator and multiclass targets"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report as eval_metrics\n",
        "from numpy import argmax\n",
        "\n",
        "y_pred =  argmax(model.predict(x_test), axis=1)\n",
        "print(eval_metrics(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNb17TkyrEAJ"
      },
      "source": [
        "## Convolutional Neural Networks\n",
        "\n",
        "Trains a simple convnet on the MNIST dataset.\n",
        "\n",
        "Gets to 99.25% test accuracy after 12 epochs\n",
        "\n",
        "There is still a lot of margin for parameter tuning.\n",
        "\n",
        "16 seconds per epoch on a GRID K520 GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7SQCY4srDiB"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKyiwJcurOeB"
      },
      "source": [
        "## LSTM Text Generator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B3LffizerR4R"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "#Example script to generate text from Nietzsche's writings.\n",
        "\n",
        "At least 20 epochs are required before the generated text\n",
        "starts sounding coherent.\n",
        "\n",
        "It is recommended to run this script on GPU, as recurrent\n",
        "networks are quite computationally intensive.\n",
        "\n",
        "If you try this script on new data, make sure your corpus\n",
        "has at least ~100k characters. ~1M is better.\n",
        "'''\n",
        "\n",
        "from __future__ import print_function\n",
        "from keras.callbacks import LambdaCallback\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.optimizers import RMSprop\n",
        "# from keras.utils.data_utils import get_file\n",
        "from keras.utils import get_file  # data_utils is no longer available for newer version of keras\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import io\n",
        "\n",
        "path = get_file(\n",
        "    'nietzsche.txt',\n",
        "    origin='https://s3.amazonaws.com/text-datasets/nietzsche.txt')\n",
        "with io.open(path, encoding='utf-8') as f:\n",
        "    text = f.read().lower()\n",
        "print('corpus length:', len(text))\n",
        "\n",
        "chars = sorted(list(set(text)))\n",
        "print('total chars:', len(chars))\n",
        "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
        "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
        "\n",
        "# cut the text in semi-redundant sequences of maxlen characters\n",
        "maxlen = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(text) - maxlen, step):\n",
        "    sentences.append(text[i: i + maxlen])\n",
        "    next_chars.append(text[i + maxlen])\n",
        "print('nb sequences:', len(sentences))\n",
        "\n",
        "print('Vectorization...')\n",
        "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        x[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "\n",
        "# build the model: a single LSTM\n",
        "print('Build model...')\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)\n",
        "\n",
        "\n",
        "def sample(preds, temperature=1.0):\n",
        "    # helper function to sample an index from a probability array\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)\n",
        "\n",
        "\n",
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "    #for diversity in [0.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        sentence = text[start_index: start_index + maxlen]\n",
        "        generated += sentence\n",
        "        print('----- Generating with seed: \"' + sentence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(sentence):\n",
        "                x_pred[0, t, char_indices[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = indices_char[next_index]\n",
        "\n",
        "            sentence = sentence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
        "\n",
        "on_epoch_end(0, 0)\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=1,\n",
        "          callbacks=[print_callback])\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
